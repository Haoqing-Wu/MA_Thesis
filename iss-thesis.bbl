% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Cx}
C.~Jones, A.~Smith and E.~Roberts, ``Article title,'' in \emph{Proceedings Title}, vol.~II.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2003, pp. 803--806.

\bibitem{peng_pvnet_2019}
\BIBentryALTinterwordspacing
S.~Peng, Y.~Liu, Q.~Huang, X.~Zhou and H.~Bao, ``\BIBforeignlanguage{en}{{PVNet}: {Pixel}-{Wise} {Voting} {Network} for {6DoF} {Pose} {Estimation}},'' in \emph{\BIBforeignlanguage{en}{2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}}.\hskip 1em plus 0.5em minus 0.4em\relax Long Beach, CA, USA: IEEE, Jun. 2019, pp. 4556--4565. [Online]. Available: \url{https://ieeexplore.ieee.org/document/8954204/}
\BIBentrySTDinterwordspacing

\bibitem{Fabian_2021}
F.~Manhardt, ``Towards monocular 6d object pose estimation,'' Ph.D. dissertation, Technische Universität München, 2021.

\bibitem{DBLP:journals/corr/abs-1711-00199}
\BIBentryALTinterwordspacing
Y.~Xiang, T.~Schmidt, V.~Narayanan and D.~Fox, ``Posecnn: {A} convolutional neural network for 6d object pose estimation in cluttered scenes,'' \emph{CoRR}, vol. abs/1711.00199, 2017. [Online]. Available: \url{http://arxiv.org/abs/1711.00199}
\BIBentrySTDinterwordspacing

\bibitem{hashim2019special}
H.~A. Hashim, ``Special orthogonal group so(3), euler angles, angle-axis, rodriguez vector and unit-quaternion: Overview, mapping and challenges,'' \emph{ArXiv preprint ArXiv:1909.06669}, 2019.

\bibitem{9231126}
V.~Mansur, S.~Reddy, S.~R and R.~Sujatha, ``Deploying complementary filter to avert gimbal lock in drones using quaternion angles,'' in \emph{2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON)}, 2020, pp. 751--756.

\bibitem{rodrigues}
G.~Terzakis, M.~Lourakis and D.~Ait-Boudaoud, ``Modified rodrigues parameters: An efficient representation of orientation in 3d vision and graphics,'' \emph{Journal of Mathematical Imaging and Vision}, vol.~60, 03 2018.

\bibitem{Zhou_2019_CVPR}
Y.~Zhou, C.~Barnes, L.~Jingwan, Y.~Jimei and L.~Hao, ``On the continuity of rotation representations in neural networks,'' in \emph{The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2019.

\bibitem{9836663}
Y.~Zhu, M.~Li, W.~Yao and C.~Chen, ``A review of 6d object pose estimation,'' in \emph{2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, vol.~10, 2022, pp. 1647--1655.

\bibitem{cao20236impose}
H.~Cao, L.~Dirnberger, D.~Bernardini, C.~Piazza and M.~Caccamo, ``6impose: Bridging the reality gap in 6d pose estimation for robotic grasping,'' 2023.

\bibitem{qin2022geometric}
Z.~Qin, H.~Yu, C.~Wang, Y.~Guo, Y.~Peng and K.~Xu, ``Geometric transformer for fast and robust point cloud registration,'' 2022.

\bibitem{fu2021robust}
K.~Fu, S.~Liu, X.~Luo and M.~Wang, ``Robust point cloud registration framework based on deep graph matching,'' 2021.

\bibitem{Besl1992AMF}
\BIBentryALTinterwordspacing
P.~J. Besl and N.~D. McKay, ``A method for registration of 3-d shapes,'' \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, vol.~14, pp. 239--256, 1992. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:21874346}
\BIBentrySTDinterwordspacing

\bibitem{auto}
R.~A. Rill and K.~Faragó, ``Collision avoidance using deep learning-based monocular vision,'' \emph{SN Computer Science}, vol.~2, 09 2021.

\bibitem{maru2022}
G.~Marullo, L.~Tanzi, P.~Piazzolla and E.~Vezzetti, ``6d object position estimation from 2d images: a literature review,'' \emph{Multimedia Tools and Applications}, vol.~82, pp. 1--39, 11 2022.

\bibitem{dataV4MUMX2020}
\BIBentryALTinterwordspacing
E.~Brachmann, ``{6D Object Pose Estimation using 3D Object Coordinates [Data]},'' 2020. [Online]. Available: \url{https://doi.org/10.11588/data/V4MUMX}
\BIBentrySTDinterwordspacing

\bibitem{hodan2017tless}
T.~Hoda{\v{n}}, P.~Haluza, {\v{S}}.~Obdr{\v{z}}{\'a}lek, J.~Matas, M.~Lourakis and X.~Zabulis, ``{T-LESS}: An {RGB-D} dataset for {6D} pose estimation of texture-less objects,'' \emph{IEEE Winter Conference on Applications of Computer Vision (WACV)}, 2017.

\bibitem{kendall2016posenet}
A.~Kendall, M.~Grimes and R.~Cipolla, ``Posenet: A convolutional network for real-time 6-dof camera relocalization,'' 2016.

\bibitem{pavlakos20176dof}
G.~Pavlakos, X.~Zhou, A.~Chan, K.~G. Derpanis and K.~Daniilidis, ``6-dof object pose from semantic keypoints,'' 2017.

\bibitem{hodan2019photorealistic}
T.~Hodan, V.~Vineet, R.~Gal, E.~Shalev, J.~Hanzelka, T.~Connell, P.~Urbina, S.~N. Sinha and B.~Guenter, ``Photorealistic image synthesis for object instance detection,'' 2019.

\bibitem{lamb2021brief}
A.~Lamb, ``A brief introduction to generative models,'' 2021.

\bibitem{goodfellow2014generative}
I.~J. Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair, A.~Courville and Y.~Bengio, ``Generative adversarial networks,'' 2014.

\bibitem{borji2018pros}
A.~Borji, ``Pros and cons of gan evaluation measures,'' 2018.

\bibitem{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala and L.~Bottou, ``Wasserstein gan,'' 2017.

\bibitem{miyato2018spectral}
T.~Miyato, T.~Kataoka, M.~Koyama and Y.~Yoshida, ``Spectral normalization for generative adversarial networks,'' 2018.

\bibitem{kingma2022autoencoding}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' 2022.

\bibitem{kingma2015variational}
D.~P. Kingma, T.~Salimans and M.~Welling, ``Variational dropout and the local reparameterization trick,'' 2015.

\bibitem{rezende2016variational}
D.~J. Rezende and S.~Mohamed, ``Variational inference with normalizing flows,'' 2016.

\bibitem{sohldickstein2015deep}
J.~Sohl-Dickstein, E.~A. Weiss, N.~Maheswaranathan and S.~Ganguli, ``Deep unsupervised learning using nonequilibrium thermodynamics,'' 2015.

\bibitem{ho2020denoising}
J.~Ho, A.~Jain and P.~Abbeel, ``Denoising diffusion probabilistic models,'' 2020.

\bibitem{nichol2022glide}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~McGrew, I.~Sutskever and M.~Chen, ``Glide: Towards photorealistic image generation and editing with text-guided diffusion models,'' 2022.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu and M.~Chen, ``Hierarchical text-conditional image generation with clip latents,'' 2022.

\bibitem{weng2021diffusion}
\BIBentryALTinterwordspacing
L.~Weng, ``What are diffusion models?'' \emph{lilianweng.github.io}, Jul 2021. [Online]. Available: \url{https://lilianweng.github.io/posts/2021-07-11-diffusion-models/}
\BIBentrySTDinterwordspacing

\bibitem{nichol2021improved}
A.~Nichol and P.~Dhariwal, ``Improved denoising diffusion probabilistic models,'' 2021.

\bibitem{song2020generative}
Y.~Song and S.~Ermon, ``Generative modeling by estimating gradients of the data distribution,'' 2020.

\bibitem{ho2022classifierfree}
J.~Ho and T.~Salimans, ``Classifier-free diffusion guidance,'' 2022.

\bibitem{yang2023diffusion}
L.~Yang, Z.~Zhang, Y.~Song, S.~Hong, R.~Xu, Y.~Zhao, W.~Zhang, B.~Cui and M.-H. Yang, ``Diffusion models: A comprehensive survey of methods and applications,'' 2023.

\bibitem{saharia2021image}
C.~Saharia, J.~Ho, W.~Chan, T.~Salimans, D.~J. Fleet and M.~Norouzi, ``Image super-resolution via iterative refinement,'' \emph{arXiv:2104.07636}, 2021.

\bibitem{ho2021cascaded}
J.~Ho, C.~Saharia, W.~Chan, D.~J. Fleet, M.~Norouzi and T.~Salimans, ``Cascaded diffusion models for high fidelity image generation,'' \emph{arXiv preprint arXiv:2106.15282}, 2021.

\bibitem{gao2023implicit}
S.~Gao, X.~Liu, B.~Zeng, S.~Xu, Y.~Li, X.~Luo, J.~Liu, X.~Zhen and B.~Zhang, ``Implicit diffusion models for continuous super-resolution,'' 2023.

\bibitem{lugmayr2022repaint}
A.~Lugmayr, M.~Danelljan, A.~Romero, F.~Yu, R.~Timofte and L.~V. Gool, ``Repaint: Inpainting using denoising diffusion probabilistic models,'' 2022.

\bibitem{saharia2022palette}
C.~Saharia, W.~Chan, H.~Chang, C.~A. Lee, J.~Ho, T.~Salimans, D.~J. Fleet and M.~Norouzi, ``Palette: Image-to-image diffusion models,'' 2022.

\bibitem{kwon2023diffusionbased}
G.~Kwon and J.~C. Ye, ``Diffusion-based image translation using disentangled style and content representation,'' 2023.

\bibitem{luo2021diffusion}
S.~Luo and W.~Hu, ``Diffusion probabilistic models for 3d point cloud generation,'' 2021.

\bibitem{zeng2022lion}
X.~Zeng, A.~Vahdat, F.~Williams, Z.~Gojcic, O.~Litany, S.~Fidler and K.~Kreis, ``Lion: Latent point diffusion models for 3d shape generation,'' 2022.

\bibitem{lyu2022conditional}
Z.~Lyu, Z.~Kong, X.~Xu, L.~Pan and D.~Lin, ``A conditional point diffusion-refinement paradigm for 3d point cloud completion,'' 2022.

\bibitem{devlin2019bert}
J.~Devlin, M.-W. Chang, K.~Lee and K.~Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' 2019.

\bibitem{Radford2018ImprovingLU}
\BIBentryALTinterwordspacing
A.~Radford and K.~Narasimhan, ``Improving language understanding by generative pre-training,'' 2018. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:49313245}
\BIBentrySTDinterwordspacing

\bibitem{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix, B.~Rozière, N.~Goyal, E.~Hambro, F.~Azhar, A.~Rodriguez, A.~Joulin, E.~Grave and G.~Lample, ``Llama: Open and efficient foundation language models,'' 2023.

\bibitem{zou2023survey}
H.~Zou, Z.~M. Kim and D.~Kang, ``A survey of diffusion models in natural language processing,'' 2023.

\bibitem{austin2023structured}
J.~Austin, D.~D. Johnson, J.~Ho, D.~Tarlow and R.~van~den Berg, ``Structured denoising diffusion models in discrete state-spaces,'' 2023.

\bibitem{hoogeboom2021argmax}
E.~Hoogeboom, D.~Nielsen, P.~Jaini, P.~Forré and M.~Welling, ``Argmax flows and multinomial diffusion: Learning categorical distributions,'' 2021.

\bibitem{li2022diffusionlm}
X.~L. Li, J.~Thickstun, I.~Gulrajani, P.~Liang and T.~B. Hashimoto, ``Diffusion-lm improves controllable text generation,'' 2022.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger and I.~Sutskever, ``Learning transferable visual models from natural language supervision,'' 2021.

\bibitem{rombach2022highresolution}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser and B.~Ommer, ``High-resolution image synthesis with latent diffusion models,'' 2022.

\bibitem{zhang2023adding}
L.~Zhang, A.~Rao and M.~Agrawala, ``Adding conditional control to text-to-image diffusion models,'' 2023.

\bibitem{poole2022dreamfusion}
B.~Poole, A.~Jain, J.~T. Barron and B.~Mildenhall, ``Dreamfusion: Text-to-3d using 2d diffusion,'' 2022.

\bibitem{ronneberger2015unet}
O.~Ronneberger, P.~Fischer and T.~Brox, ``U-net: Convolutional networks for biomedical image segmentation,'' 2015.

\bibitem{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J\'egou, J.~Mairal, P.~Bojanowski and A.~Joulin, ``Emerging properties in self-supervised vision transformers,'' in \emph{Proceedings of the International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{yang2018foldingnet}
Y.~Yang, C.~Feng, Y.~Shen and D.~Tian, ``Foldingnet: Point cloud auto-encoder via deep grid deformation,'' 2018.

\bibitem{121791}
P.~Besl and N.~D. McKay, ``A method for registration of 3-d shapes,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~14, no.~2, pp. 239--256, 1992.

\bibitem{vaswani2023attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~Kaiser and I.~Polosukhin, ``Attention is all you need,'' 2023.

\bibitem{dosovitskiy2021image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit and N.~Houlsby, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' 2021.

\end{thebibliography}
