% -----------------------------------------------------------------
% Vorlage fuer Ausarbeitungen von
% Bachelor- und Masterarbeiten am ISS
% 
% Template for written reports or master theses at the ISS
% 
% For use with compilers pdflatex or latex->dvi2ps->ps2pdf.
%
% -----------------------------------------------------------------
% README, STUDENT USERS:
% We highly appreciate students using this template _AS IS_,period. 
% The document provides adjustable document preferences, 
% student information settings and typography definitions. Look for
% code delimited by *** ***
%
% The short explanation: it's the ISS common standard and 
% 	it's battle tested.
% The long explanation: 
%	We do not want you to go through the document and tweak the 
%	package options, layout parameters and line skips here and 
%	there and waste hours. We are providing this template such 
%	that you can fully concentrate on filling in the much more 
%	important _contents_ of your thesis.
%
% If you have serious needs on extra packages or design 
% modifications, talk to your supervisor _before_ modifying 
% the template.
% Similarly, we're happy if you give your supervisor a hint on any 
% errors in this template.
%
% -----------------------------------------------------------------
% History:
% Jan Scheuing,   04.03.2002
% Markus Buehren, 20.12.2004
% last changes:   10.01.2008 (removed unused packages), 
% 		07.08.2009 (added IEEEtran_LSS.bst file)
% 		02.05.2011 removed matriculation number from cover page
% Martin Kreissig, 25.01.2012: all eps/ps parts removed for 
% 				pdflatex to work properly
% Peter Hermannstaedter, 14.08.2012: fusion of versions for 
% 		latex/dvi/ps/pdf and pdflatex, additional comments,
% 		unification of document flags and student options
% Florian Liebgott, 12.03.2015: bug fixes, removal of obsolete options,
%		switch to UTF-8
% Florian Liebgott, 20.05.2015: fixed encoding problem on title page
% Florian Liebgott, 24.01.2017: changed deprecated font commands (like
%		\sl) to up-to-date commands to be compatible with
%		current TeX distributions.
% Felix Wiewel, 30.08.2021: Replace obsolete scrpage2 with scrlayer-scrpage
%
% -----------------------------------------------------------------
% If you experience any errors caused by this template, please
% contact Florian Liebgott (florian.liebgott@iss.uni-stuttgart.de)
% or your supervisor, so we can fix the errors.
% -----------------------------------------------------------------


\documentclass[12pt,DIV14,BCOR12mm,a4paper,footinclude=false,headinclude,parskip=half-,twoside,openright,cleardoublepage=empty,toc=index,bibliography=totoc,listof=totoc]{scrreprt}
% encoding needs to be defined here, otherwise umlauts on the titelpage won't work.
\usepackage[utf8]{inputenc}
%
%
%
% *****************************************************************
% -------------------> document preferences here <-----------------
% *****************************************************************
% Uncomment the settings you like and comment the settings you don't
% like.

% Language: 
% affects generic titles, Figure term, titlepage and bibliography
% (Note:if you switch the language, compile tex and bib >2 times)
\def \doclang{english} 	% For theses/reports in English
%\def \doclang{german} 		% For theses/reports in German

% Hyperref links in the document:
\def \colortype{color} % links with colored text
%\def \colortype{bw} 	% plain links, standard text color (e.g. for print)
%\def \colortype{boxed} % links with colored boxes
% *****************************************************************
%
%
%
% *****************************************************************
% --------------> put student information here <------------------
% *****************************************************************
% Please fill in all items denoted by "to be defined (TBD)"
\def \deworktitle{Arbeitstitel, to be defined (TBD)}        % German title/translation
\def \enworktitle{Thesis title TBD}        % English title/translation
\def \tutor{Supervisor's name TBD}
\def \student{Student's name TBD}
\def \worksubject{Masterarbeit Dxxxx TBD}  % type and number (S/Dxxxx) of your thesis
\def \startdate{Date of work begin TBD}
\def \submission{Date of submission TBD}
\def \signagedate{TBD Date of sign.}   % Date of signature of declaration on last page
\def \keywords{Keyword1, Keyword2 TBD}
\def \abstract{Abstract TBD}

% *****************************************************************
%


\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{ifthen}
\ifthenelse{\equal{\doclang}{german}}{
	\usepackage[ngerman]{babel} %german version
	\def \maintitle{\deworktitle}
	\def \translatedtitle{\enworktitle}
	% set , to decimal and . to thousands separator, if German language is used
	\DeclareMathSymbol{,}{\mathord}{letters}{"3B}
	\DeclareMathSymbol{.}{\mathpunct}{letters}{"3A}
	}{
	%english version
	\def \maintitle{\enworktitle}
	\def \translatedtitle{\deworktitle}
	}
\usepackage{txfonts} % Times-Fonts
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage[headsepline]{scrlayer-scrpage} % Headings

\usepackage{graphicx}
\usepackage[format=hang]{caption}       % for hanging captions
\usepackage{subfig}                     % for subfigures
\usepackage{wrapfig}                    % for figures floating in text, alternatively you can use >>floatflt<<
\usepackage{booktabs}                   % nice looking tables (for tables with ONLY horizontal lines)

%%%%% Tikz / PGF - drawing beautiful graphics and plots in Latex
% \usepackage{tikz}
% \usetikzlibrary{plotmarks}              % larger choice of plot marks
% \usetikzlibrary{arrows}                 % larger choice of arrow heads
% % ... insert other libraries you need
% \usepackage{pgfplots}
% % set , to decimal and . to thousands separator for plots, if German language is used
% \ifthenelse{\equal{\doclang}{german}}{
% \pgfkeys{/pgf/number format/set decimal separator={,}}
% \pgfkeys{/pgf/number format/set thousands separator={.}}
% }{}
%%%%%%

\ifthenelse{\equal{\colortype}{color}}{
	% colored text version:
	\usepackage[colorlinks,linkcolor=blue]{hyperref}
	\newcommand{\bugfix}{\color{white}{\texttt{\symbol{'004}}}} % Bug-Fix Umlaute in Verbatim
}{
	\ifthenelse{\equal{\colortype}{boxed}}{
		% colored box version:
		\usepackage{hyperref}
		\newcommand{\bugfix}{\color{white}{\texttt{\symbol{'004}}}} % Bug-Fix Umlaute in Verbatim
	}{
		% monochrome version:
		\usepackage[hidelinks]{hyperref}
		\newcommand{\bugfix}{\color{white}{\texttt{\symbol{'004}}}} % Bug-Fix Umlaute in Verbatim
	}
}

% Layout and Headings
\pagestyle{scrheadings}
\automark{chapter}
\clearscrheadfoot
\lehead[]{\pagemark~~\headmark}
\rohead[]{\headmark~~\pagemark}
\renewcommand{\chaptermark}[1]{\markboth {\normalfont\slshape \hspace{8mm}#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\normalfont\slshape \thesection~#1\hspace{8mm}}}
\addtolength{\textheight}{15mm}
\parindent0ex
\setlength{\parskip}{5pt plus 2pt minus 1pt}
\renewcommand*{\pnumfont}{\normalfont\slshape} % Seitenzahl geneigt
\renewcommand*{\sectfont}{\bfseries} % Kapitelueberschrift nicht Helvetica

% Settings for PDF document
\pdfstringdef \studentPDF {\student} 
\pdfstringdef \worktitlePDF {\maintitle}
\pdfstringdef \worksubjectPDF {\worksubject}
\hypersetup{pdfauthor=\studentPDF, 
            pdftitle=\worktitlePDF,
            pdfsubject=\worksubjectPDF}

% Title page
\titlehead{
	\includegraphics[width=20mm]{university-logo}
	\hspace{6mm}
	\ifthenelse{\equal{\doclang}{german}}{
		\begin{minipage}[b]{.6\textwidth}
		{\Large Universit\"at Stuttgart } \\
		Institut f\"ur Signalverarbeitung und Systemtheorie\\
		Professor Dr.-Ing. B. Yang \vspace{0pt}
		\end{minipage}
	}{
		\begin{minipage}[b]{.6\textwidth}
		{\Large University of Stuttgart } \\
		Institute for Signal Processing and System Theory\\
		Professor Dr.-Ing. B. Yang \vspace{0pt}
		\end{minipage}
	}
	\hspace{1mm}
	\includegraphics[width=28mm]{isslogocolor}
}
\subject{\worksubject\vspace*{-5mm}} % Art und Nummer der Arbeit
\title{\maintitle}%\\ \Large{\subtitle}}
\subtitle{\translatedtitle}
\author{
\large
  \ifthenelse{\equal{\doclang}{german}}{
  \begin{tabular}{rp{7cm}}
    \Large 
    Autor:      & \Large \student \vspace*{2mm}\\
    Ausgabe:    & \startdate \\
    Abgabe:     & \submission \vspace*{3mm}\\
    Betreuer:   & \tutor \vspace*{2mm}\\
    Stichworte: & \keywords
  \end{tabular}
  }{
  \begin{tabular}{rp{7cm}}
    \Large 
    Author:             & \Large \student \vspace*{2mm}\\
    Date of work begin: & \startdate \\
    Date of submission: & \submission \vspace*{3mm}\\
    Supervisor:         & \tutor \vspace*{2mm}\\
    Keywords:           & \keywords
  \end{tabular}
  }
  \bugfix
}
\date{}
\publishers{\normalsize
  \begin{minipage}[t]{.9\textwidth}
    \abstract
  \end{minipage}
}

\numberwithin{equation}{chapter} 
\sloppy 

%
%
%
% *****************************************************************
% --------------> put typography definitions here <----------------
% *****************************************************************
% colors
\definecolor{darkblue}{rgb}{0,0,0.4}

% declarations
\newcommand{\matlab}{\textsc{Matlab}\raisebox{1ex}{\tiny{\textregistered}} }
% Integers, natural, real and complex numbers
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
% expectation operator
\newcommand{\E}{\operatorname{E}}
% imaginary unit
\newcommand{\im}{\operatorname{j}}
% Euler's number with exponent as parameter, e.g. \e{\im\omega}
\newcommand{\e}[1]{\operatorname{e}^{\,#1}}
% short command for \operatorname{}
\newcommand{\op}[1]{\operatorname{#1}}

% unknown hyphenation rules
\hyphenation{Im-puls-ant-wort Im-puls-ant-wort-ko-ef-fi-zien-ten
Pro-gramm-aus-schnitt Mi-kro-fon-sig-nal}
% *****************************************************************
%
\begin{document}

% title and table of contents
\pagenumbering{alph}
\maketitle
\cleardoublepage
\pagenumbering{roman} % roman numbering for table of contents
\tableofcontents
\cleardoublepage
\setcounter{page}{1}
\pagenumbering{arabic} % arabic numbering for rest of document

% *****************************************************************
% -------------------> start writing here <------------------------

\chapter{Introduction}
\section{Motivation}

\section{Main Objective}

\section{Structure of the Thesis}

As shown in \cite{Cx}, we present an equation
\begin{align}
	H(\omega) = \int h(t) \e{\im\omega t} \delta t \in \N
\end{align}

Then we include a graphic in figure \ref{mind} and information about captions in table \ref{captions}.\\
\begin{figure}
	\centering
	\includegraphics[scale=.3]{isslogocolor}
	\caption{A beautiful mind}
	\label{mind}
\end{figure}

\begin{table}
    \centering
    \caption{Where to put the caption}
    \label{captions}
    \begin{tabular}{lcc}
        \toprule
         & above & below\\
        \midrule
        for figures & no & yes\\
        for tables & yes & no\\
        \bottomrule
    \end{tabular}
\end{table}


Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.
\newpage
Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

\chapter{Background}
\section{6 DoF Pose Estimation}
\subsection{Definition}
Six degree-of-freedom(DoF) pose refers to the six degrees of freedom of movement of a rigid body in three-dimensional space. 
Especially, it represents the freedom of a rigid body to move in three perpendicular directions, called translations, and to rotate about three perpendicular axes, 
called rotations. This concept is widely applied in the industial and automotive field to measure and analyize the spacial properties of objects.

In domain of computer vision and robotics, 6 DoF pose estimation is a fundamental task that aims to estimate the 3D translation $t=(t_{x} ,t_{y} ,t_{z} )$ 
and rotation $R=(\Phi_{x} ,\Phi_{y} ,\Phi_{z} )$ of an object related to a canonical coordinate system using the sensor input, such as RGB or RGB-D data\cite{peng_pvnet_2019}.
The object $M$ is typically a known 3D CAD model, consisting of a set of vertices $V=\{v_1,...,v_N\}$, 
with $v_i\in \mathbb{R}^3$ and $V\in \mathbb{R}^{3 \times N}$ and triangles $E=\{e_1,...,e_M\}$, 
with $e_i\in \mathbb{R}^3$ and $E\in \mathbb{R}^{3\times M}$ connecting the vertices. 
Furthermore, if the query image is a multi-object scenario with N objects $O=\{M_1,...,M_N\}$, 
we need to detect and estimate the pose of each object $M_i$ in the image\cite{Fabian_2021}.

-----------------image here----------------
\subsection{Representing 6 DoF Pose}
6 DoF pose can be treated seperately as 3D translation and 3D rotation. 
The 3D translation is simply represented by 3 scalars along the X, Y, and Z axis of the canonical coordinate system. 
We can use either the deep learning methods to estimate the depth and the corresponding 2D projection from RGB images 
or even get the depth information fused from RGB-D data\cite{DBLP:journals/corr/abs-1711-00199}. 
After that, the object can be shifted back to the camera coordinate system by adding translation vector to the object vertices $V$
\begin{align}
  V^{'} = V + \textbf{t}
\end{align}
Similarly, the 3D rotation can be represented by 3 rotation matrics around the X, Y and Z axis. 
And rotating the object vertices $V$ by the rotation matrix $\textbf{R}_{i}$ with $i\in \{X,Y,Z\}$ can be achieved by multiplying them. 
Rotation around X axis is defined as
\begin{align}
  V^{'} = \textbf{R}_{X}(\Phi_{x})V = \begin{bmatrix}
    1 & 0 & 0 \\
    0 & cos(\Phi_{x}) & -sin(\Phi_{x}) \\
    0 & sin(\Phi_{x}) & cos(\Phi_{x})
  \end{bmatrix}V
\end{align}
Rotation matrix $\textbf{R}_{Y}$ and $\textbf{R}_{Z}$ can be defined repectively with
\begin{align}
  \textbf{R}_{Y}(\Phi_{y}) = \begin{bmatrix}
    cos(\Phi_{y}) & 0 & sin(\Phi_{y}) \\
    0 & 1 & 0 \\
    -sin(\Phi_{y}) & 0 & cos(\Phi_{y})
  \end{bmatrix}
\end{align}
\begin{align}
  \textbf{R}_{Z}(\Phi_{z}) = \begin{bmatrix}
    cos(\Phi_{z}) & -sin(\Phi_{z}) & 0 \\
    sin(\Phi_{z}) & cos(\Phi_{z}) & 0 \\
    0 & 0 & 1
  \end{bmatrix}
\end{align}
The rotation matrix $\textbf{R}$ can be obtained by multiplying the three rotation matrices $\textbf{R}_{X}$, $\textbf{R}_{Y}$ and $\textbf{R}_{Z}$ together, 
but changing the order of the multiplication will result in different rotation matrix. The common order is defined a $Z-Y-X$ order, 
which means the rotation around X axis is performed first, then Y axis and finally Z axis. All possible rotations in 3D Euclidean space establish 
a natual manifold known as special orthognal group $\mathbb{S} \mathbb{O} (3)$\cite{hashim2019special}.

Togather with the translation vector $\textbf{t}$, the 6 DoF pose can be represented by a 4x4 transformation matrix $\textbf{T}$ as
\begin{align}
  \textbf{T} = \begin{bmatrix}
    \textbf{R} & \textbf{t} \\
    0 & 1
  \end{bmatrix}
  = \begin{bmatrix}
    r_{11} & r_{12} & r_{13} & t_{1} \\
    r_{21} & r_{22} & r_{23} & t_{2} \\
    r_{31} & r_{32} & r_{33} & t_{3} \\
    0 & 0 & 0 & 1
  \end{bmatrix}
  \in \mathbb{S} \mathbb{E} (3)
\end{align}
The partitioned transformation matrix with 3x3 rotation matrix $\textbf{R}$ and a column vector $\textbf{t}$ that represents the translation 
is also called homogeneous representation of a transformation. All possible transformation matrices of this form generate the 
special Euclidean group $\mathbb{S} \mathbb{E} (3)$
\begin{align}
  \mathbb{S} \mathbb{E} (3) = \{\textbf{T} = \begin{bmatrix}
    \textbf{R} & \textbf{t} \\
    0 & 1
  \end{bmatrix}\in \mathbb{R}^{4 \times 4}| \textbf{R} \in \mathbb{S} \mathbb{O} (3), \textbf{t} \in \mathbb{R}^{3} \}
\end{align}
An alternative representation of 6 DoF pose is a 7-dimensional vector that consists of translation and rotation quaternion which has a compacter form
\begin{align}
  \textbf{T} = (t_{x}, t_{y}, t_{z}, q_{w}, q_{x}, q_{y}, q_{z})^{T}
\end{align}
Where the quaternion $q$ is defined as
\begin{align}
  q = q_{w} + q_{x}i + q_{y}j + q_{z}k \quad \textrm{with} \quad i^{2} = j^{2} = k^{2} = ijk = -1
\end{align}
Normally, regressing the rotation matrix directly is not a common choice since the same rotation can be achieved via different combinations of Euler angles. 
And the unit quaterion form is in many case prefered because it can ensure the uniqueness by restricting the quaterion on the upper hemisphere of $q_{w}=0$ plane 
and can also guarantee a gimbal-lock free rotation in $\mathbb{S} \mathbb{O} (3)$\cite{9231126}. 
However, rotation matrix is widely used in many dataset to represent the ground truth transformation. 
\subsection{Applications}
6 DoF pose estimation is a central technology that can be the critical part of many computer vision applications such as 
augmented reality(AR), robotics, 3D scene understanding and autonomous driving.

\subsubsection{Augmented Reality}
AR applications use 6 DoF pose estimation to accurately place the virtual objects in the real world. 
With precise estimation and quick inference of the pose guarantee a immersive and interactive experience 
which is the direction of the development of AR applications\cite{9836663}. 
Furthermore, 6 DoF pose estimation can also be utilized to track the real world objects, enabling more natural interactions.

\subsubsection{Robotics}
6 DoF pose estimation helps robots to understand the scene so that the grasping and manipulation of objects can be achieved. 
In the field of medical robotics, it can be used to track the surgical instrument or a patient's body part\cite{cao20236impose}. 
In manufacturing, robots use the estimated pose to identify, sort and assemble the objects in field like automatic logistic sorting and manufacturing line.

\subsubsection{3D Scene Understanding}
In order to register the 3D objects into the scene or reconstruct the 3D environment from 2D images or 3D point clouds, 6 DoF pose estimation is required. 
The alignment of the 3D objects or 3D scenes is realized by estimating the rigid transformation using method like correspondance matching\cite{qin2022geometric} 
or direct transformation estimation\cite{fu2021robust} follows the ideas of ICP\cite{Besl1992AMF}.

\subsubsection{Autonomous Driving}
Autonomous driving is also a cross-domain topic that requires many different technologies to work together. 
A well estimated pose of the vehicle inside the scene is the basis of many other subtasks of autonomous driving such as collision avoidance,
trajectory planning and so on. Subtle errors in the pose estimation may lead to fatal consequences\cite{auto}, because the vehicle move normally in high speed 
and the heading direction cause a large deviation in a long distance considering also the reaction time of the vehicle.
\subsection{Challenges}
6 DoF pose is widely used in many applications and became a popular research topic of computer vision in recent years. 
However, solving this problem is not trivial and even challenging in many cases.

First constrain would be the auto-occlusion or symmetries of the object since the object cannot be clearly and unequivocally observed from all angles\cite{maru2022}.
The auto-occlusion means that the object itself is partially occluded by other parts of the object such as LINEMOD-O dataset\cite{dataV4MUMX2020}. 
This is common in many real world objects such as table or chair. The symmetries of the object means that the object has same appearance from different angles, 
which will cause ambiguity in the estimation such as T-LESS dataset\cite{hodan2017tless}. 
Imagining an image of mug with the handle hidden behind it, it is hard to tell the orientation of the mug without the handle.

Textureless object is also a challenge for 6 DoF pose estimation, since many methods rely not only on the geometry of the object but also on the texture. 
It is hard for RGB-only methods\cite{kendall2016posenet} or keypoint based method\cite{pavlakos20176dof} to extract enough local features if the object is complete textureless.

Another difficulty is the domain gap between the training and testing data. Normally, the training data consists of synthetic CAD models and images 
which are clean and annotated with the ground truth pose in order to have a precise supervision. But lacking the information of the real world, 
for example lighting and occlusion, the model trained on the synthetic data cannot generalize well to the real world data. 
Some dataset provides the real world data or 3D rendered images which can reduce the domain gap in some degree\cite{hodan2019photorealistic}, 
but the noise and unvalid training samples still confuse the model.

If facing the multi-object scenario, which is common in the application like robotics and autonomous driving, 
the unknown number and type of objects will increase the difficulty of pose estimation for each object in the scene.

-----------------image here----------------

\section{Diffusion Model}
\subsection{Generative Models}
One of the most fascinating and distinctive feature of human brain is the ability to create or imagine objects that do not immediately exist in reality. 
Humans can spontaneouesly learn the underlying properties of the world and generate the hypotheses of the future. 
This procedure is similiar to supervised learning and reinforcement learning with little mount of labeled data, 
but generalizes very well to many unseen scenarios and has a high level of robustness\cite{lamb2021brief}.

In order to achieve the similiar ability of the generative process from the human brain, many generative models have been proposed in recent years, 
to not really synthesize the unseen data but to recover or modifiy the seen data with given constraints. Some of the most popular generative models are introduced below.

\subsubsection{Generative Adversarial Networks}
Generative Adversarial Networks(GANs)\cite{goodfellow2014generative} is a smart idea to train a generative model by playing a min-max game between two neural networks.
The generator $G$ is trained to generate data that is indistinguishable from the real data, 
while the discriminator $D$ is trained to distinguish the real data from the fake data generated by $G$.
The training process can be formulated as the value function $V(D,G)$, and for the classification objective using cross entropy loss, the optimization problem can be written as
\begin{align}
  \min_{G} \max_{D} V(D,G) = \mathbb{E}_{x\sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]
\end{align}
The generator is optimized to maximize the probability of that the discriminator will classify the generated data as real, which explains the word "adversarial" in the name of GANs.

-----------------image here----------------

GANs have shown a great success in many applications such as generating high-resolution images which are difficult to distinguish from the real ones 
and the ability to learn the complicated distributions. However, the main challenge of GANs is the instablitity of the training process, 
which increases the difficulty of training and tuning the model. It will sometimes suffer from the mode collapse problem, 
where the generator only learns to generate a subset of the data distribution\cite{borji2018pros}.

Some works have been done to solve these problems. For example, Wasserstein GANs\cite{arjovsky2017wasserstein} use a different loss function to stablize the training process 
and avoid the mode collapse. Spectral Normalization\cite{miyato2018spectral} is another method to stablize the training process by 
constraining the Lipschitz constant of the discriminator.
\subsubsection{Variational Autoencoders}
Variational autoencoders(VAEs)\cite{kingma2022autoencoding} is another popular generative model that is based on the encoder-decoder architecture. 
It allows the model to learn the latent representation of the input data and generate new data from the latent space. 
The encoder $E$ is trained to map the input data $x$ to the latent space $z$ with a distribution $q(z|x)$,
while the decoder $D$ is trained to reconstruct the input data from the latent space $z$ with a distribution $p(x|z)$. The training process can be formulated as
\begin{align}
  \min_{E,D} \mathbb{E}_{x\sim p_{data}(x)}[\mathbb{E}_{z\sim q(z|x)}[\log p(x|z)]] - KL(q(z|x)||p(z))
\end{align}
The first term is the reconstruction loss, which is the negative log-likelihood of the input data $x$ given the latent representation $z$.
The second term is the regularization term, which is the Kullback-Leibler divergence between the latent distribution $q(z|x)$ and the prior distribution $p(z)$.
With the regularisation term, we prevent the model to encode the input data far apart in the latent space, which will cause the model to generate unrealistic data.

-----------------image here----------------

And the reparameterization trick\cite{kingma2015variational} is introduced afterwards to make the stochastic part of the loss function 
which is the latent representation $z$ differentiable, so that the model can be trained with backpropagation. 
The latent representation $z$ is sampled from a distribution $q(z|x)$, which is normally a Gaussian distribution.
The trick constructs the random variable $z$ into following expression where $\epsilon$ is a random variable sampled from a standard Gaussian distribution.
\begin{align}
  z \in \mathcal{N} (\mu, \sigma^{2}) \longrightarrow z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N} (0, 1)
\end{align}
VAEs allow us to easily sample the latent representation $z$ from the prior distribution $p(z)$ and generate novel data from the decoder $D$.
It can alse be used to make data compression and denoising, which is the main application of autoencoders. Since the flexibility and the robustness of VAEs,
It is widely used in many applications such as image manipulation, text generation and speech synthesis.
\subsubsection{Normalizing Flows}
Normalizing flows\cite{rezende2016variational} are a familiy of generative models with tractable marginal likelihood which can not be achieved with VAEs.
A normalizing flow is a transformation of a simple distribution into a more complex distribution by a series of invertible and differentiable mappings.
By repeating the rule of transformation, the initial probability densitiy "flows" through the sequence of invertible mappings and become a valid distribution.

-----------------image here----------------

The basic rule for transformation of densities considers an inverible, smooth mapping $f: \mathbb{R}^{D} \rightarrow \mathbb{R}^{D}$,
with inverse $f^{-1} = g$. Transforming a random variable $z$ with distribution $q(z)$ through $f$ results in a random variable $z^{'}  = f(z)$ has a distribution:
\begin{align}
  q(z^{'}) = q(z) \left| \det \frac{\partial f^{-1}}{\partial z^{'}} \right| = q(z) \left| \det \frac{\partial f}{\partial z} \right|^{-1}
\end{align}
The last term is the Jacobian determinant of the transformation $f$, which is the determinant of the matrix of partial derivatives of $f$ with respect to $z$.
Given a chain of invertible mappings $f_{1},...,f_{K}$, the transformation of the random variable $z$ through the sequence of mappings 
and the density $q_{K}(z)$ can be written as
\begin{gather}
  z_{K} = f_{K} \cdot ... f_{2} \cdot f_{1}(z_{0})\\
  lnq_{K}(z_{K}) = lnq_{0}(z_{0}) - \sum_{k=1}^{K} ln \left| \det \frac{\partial f_{k}}{\partial z_{k-1}} \right|
\end{gather}
The path of the transformation can be seen as a flow of the probability density from the initial distribution $q_{0}(z_{0})$ to the final distribution $q_{K}(z_{K})$.
If the length of the normalizing flow tends to infinity, the model becomes an infinitesimal flow which is described by a differential equation.

Normalizating flows provide a flexible framework for modeling complex distributions, which is difficult to achieve with previous generative models.
However the samples that are generated througn flow-based models are not as realistic as the samples from GANs or VAEs, 
and the data will be projected into also high dimensional space, which is hard to interpret.

\subsubsection{Transformer}
---------------Add if needed----------------

\subsubsection{Diffusion Model}
Diffusion models are a new class of state-of-the-art generative models that can synthesize high-quality images in recent years. The representative one, 
which is the Denosing Diffusion Probabilistic Models(DDPM) was initialized by Sohl-Dickstein et al\cite{sohldickstein2015deep} 
and proposed recently by Ho. et al\cite{ho2020denoising}. 

A diffusion probabilistic model(diffusion model), inspired by the nonequilibrium thermodynamics,
is a parameterized Markov chain trained using variational inference to produce samples from a given target distribution after finite steps.
The basic idea behind diffusion models is trivial. Given an input data $x_{0}$, we first gradually add Gaussian noise to it 
and finally get a sequence of noised data $x_{1},...,x_{T}$, which we call it forward process. Afterward, 
a neural network is trained to recover the original data by estimating the noise and reversing the forward precess, which we call it sampling process or reverse process.

-----------------image here----------------

The great succuss of some architecture using the diffusion model such as GLIDE\cite{nichol2022glide} 
and DALLE-2/3\cite{ramesh2022hierarchical} has shown the potential of the diffusion model in the field of generative models.
The advantage of diffision model is that it is large-scale, flexible and offer high-quality samples. 
With the tradeoff of the relative longer training time and inference time because of its 2-phases architecture, 
it can synthesize highest-quality images than other generative models. This potential motivates us to apply the diffusion model also to 3D domain and the related tasks.

-----------------image here----------------

\subsection{Theory and Fundamentals}
In this section, we will introduce the detail of the diffusion model, the mathematical background in the forward process and the sampling process, and the training process.
The extended version of the classic DDPM will also be briefly introduced.

\subsubsection{Forward Process}
Given an input data $x_{0}$ from the target data distribution $q(x)$, we first define a forward process that gradually adds Gaussian noise to 
$x_{0}$ with variance $\beta_{t}\in (0, 1)$ at each step $t$ and finally get a sequence of noised data $x_{1},...,x_{T}$. 
At each step $t$, we have the new data $x_{t}$ with the conditional distribution $q(x_{t}|x_{t-1})$ defined as:
\begin{align}
  q(x_{t}|x_{t-1}) = \mathcal{N}(x_{t}; \sqrt{1-\beta_{t}}x_{t-1}, \beta_{t}\textbf{I})
\end{align}
where $q(x_{t}|x_{t-1})$ is a normal distribution with mean $\sqrt{1-\beta_{t}}x_{t-1}$ and variance $\beta_{t}\textbf{I}$. 
Thus, we can derive the posterior distribution from the input data $x_{0}$ to $x_{T}$ in a tractable way:
\begin{align}
  q(x_{1:T}|x_{0}) = \prod_{t=1}^{T}q(x_{t}|x_{t-1})
\end{align}

-----------------image here----------------

Our goal is to track the noised data at an arbitrary step $t$ with a close-form posterior distribution $q(x_{t}|x_{0})$. 
So the reparemeterization trick is introduced so that we don't need to calculate the $x_{t}$ iteratively from $t=0$.

Let $\alpha_{t} = 1 - \beta_{t}$ and $\bar{\alpha}_{t} = \prod_{i=1}^{t}\alpha_{i}$ 
with Gaussian noise $\epsilon_{0},...,\epsilon_{t-2},\epsilon_{t-1} \sim \mathcal{N}(0, \textbf{I})$,
we can simplify the noised the data $x_{t}$ in such a recursive way:
\begin{align*}
  x_{t} &= \sqrt{\alpha_{t}}x_{t-1} + \sqrt{1-\alpha_{t}}\epsilon_{t-1}\\
        &= \sqrt{\alpha_{t}}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_{t}}\epsilon_{t-1}\\
        &= \sqrt{\alpha_{t}\alpha_{t-1}}x_{t-2} + \sqrt{\alpha_{t}(1-\alpha_{t-1})}\epsilon_{t-2} + \sqrt{1-\alpha_{t}}\epsilon_{t-1}
\end{align*}
Notice that when we merge two Gaussian distributions with different variance, $\mathcal{N} (0, \sigma^{2}_{1}\textbf{I})$ and $\mathcal{N} (0, \sigma^{2}_{2}\textbf{I})$,
the new merged distribution is $\mathcal{N} (0, (\sigma^{2}_{1} + \sigma^{2}_{2})\textbf{I})$. 
So we can merge the second and third term in the equation above where $\bar{\epsilon}_{t-2}$ is the new distribution and get:
\begin{align}
  x_{t} &= \sqrt{\alpha_{t}\alpha_{t-1}}x_{t-2} + \sqrt{\alpha_{t}(1-\alpha_{t-1})}\epsilon_{t-2} + \sqrt{1-\alpha_{t}}\epsilon_{t-1}\notag\\
        &= \sqrt{\alpha_{t}\alpha_{t-1}}x_{t-2} + \sqrt{\alpha_{t}(1-\alpha_{t-1}) + (1-\alpha_{t})}\bar{\epsilon}_{t-2}\notag\\
        &= \sqrt{\alpha_{t}\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t}\alpha_{t-1}}\bar{\epsilon}_{t-2}\notag\\
        &=...\notag\\
        &= \sqrt{\bar{\alpha}_{t}}x_{0} + \sqrt{1-\bar{\alpha}_{t}}\epsilon
\end{align}
Finally, we can represent the sample $x_{t}$ with the following distribution:
\begin{align}
  x_{t} \sim q(x_{t}|x_{0}) = \mathcal{N}(x_{t}; \sqrt{\bar{\alpha}_{t}}x_{0}, (1-\bar{\alpha}_{t})\textbf{I})
\end{align}
where $\alpha_{t}$ and $\bar{\alpha}_{t}$ can be precomputed for an arbitrary step $t$ and sample out noised variable $x_{t}$ from the distribution.
\subsubsection{Reverse Process}

\subsubsection{Training Process}

\subsubsection{Conditional Diffusion Model}

\subsubsection{Extensions}

\subsection{Applications}

\chapter{Related Work}

\chapter{Methodology}

\chapter{Experiments}

\chapter{Discussion}

\chapter{Conclusion}

\appendix
\chapter{Additionally}
You may do an appendix



% -------------------> end writing here <------------------------
% *****************************************************************
\listoffigures
\listoftables

\ifthenelse{\equal{\doclang}{german}}{
	\bibliographystyle{IEEEtran_ISSger}
}{
	\bibliographystyle{IEEEtran_ISS}
}
\bibliography{refs}

% *****************************************************************
%% Additional page with Declaration ("Eidesstattliche Erklrung");
%% completed automatically
\begin{titlepage}
      \vfill
      \LARGE \ifthenelse{\equal{\doclang}{german}}{\textbf{Erkl\"arung}}{\textbf{Declaration}}
      \vfill

      \ifthenelse{\equal{\doclang}{german}}{
         Hiermit erkl\"are ich, dass ich diese Arbeit selbstst\"andig verfasst und keine anderen als die angegebenen
         Quellen und Hilfsmittel benutzt habe.
      }
      {
         Herewith, I declare that I have developed and written the enclosed thesis entirely by myself and that I have not used sources or means except those declared.
      }

      \vspace{1cm}

      \ifthenelse{\equal{\doclang}{german}}{
         Die Arbeit wurde bisher keiner anderen Pr\"ufungsbeh\"orde vorgelegt und auch noch nicht ver\"offentlicht.
      }
      {
         This thesis has not been submitted to any other authority to achieve an academic grading and has not been published elsewhere.
      }

      \vfill

      
      Stuttgart, \signagedate
      \hfill
      \begin{tabular}{l}
          \hline
          \student
      \end{tabular}
\end{titlepage}



\end{document}
